# ğŸ”“ Under the Hood: Unpacking Git's Secrets
**Partâ€¯3: One Index to Rule Them AllÂ â€“ The Multiâ€‘Pack Index**

> *Missed the journey so far? In* [PartÂ 1](./part1.md) *we asked why a secretâ€‘scanner should talk to Gitâ€™s storage directly, and in* [PartÂ 2](./part2.md) *we learned how a single packâ€‘index lets us jump to any object in O(1). Today weâ€™re scaling that trick to **hundreds** of packfiles without breaking a sweat.*

---

## ğŸššÂ Why Lots of Packfiles Slow UsÂ Down

When Git runs `git gc`, fetches from remotes, or writes a shallow clone, it often **creates a brandâ€‘new `.pack` file** instead of rewriting the existing one. Over time even a modestâ€‘sized repository can balloon from a single pack to dozens or hundreds:

* fresh repo after first commitÂ â€“ **1 pack**
* three months of active feature workÂ â€“ **17 packs**
* three years of CI fetches and GC cyclesÂ â€“ **â‰ˆ150 packs**

Using the perâ€‘pack `.idx` we built in PartÂ 2, each object lookup is forced to do a tiny binary search **inside *every* pack**:

```text
for each .idx (N)
    binaryâ€‘search for <hash>
```

A few microseconds Ã— 150 packs Ã— millions of lookups quickly turns into minutes of wasted CPU.

**Gitâ€™s answer is the _multiâ€‘pack index_** (`.midx`). It flattens all those perâ€‘pack fanâ€‘out tables into one master index so we pay the binaryâ€‘search cost exactly **once**, no matter how many packs exist.

## ğŸ“šÂ AnalogyÂ â€“ The Cityâ€‘Wide Library Catalogue

> *Think of every packfile as a branch library.*
>
> *The MIDX is the cityâ€™s central catalogue: search once, learn the branchÂ + shelf, then go straight there.*

If you enjoyed the cardâ€‘catalogue metaphor in PartÂ 2, nothing changes â€“ we simply graft every branchâ€™s catalogue into one gigantic, ordered list. The fanout table still tells us the aisle; the binary search still finds the card. We just tack on **â€œbranchÂ IDâ€** next to the **â€œshelf offsetâ€**.

---

## ğŸ—ï¸Â MIDX File Anatomy at 10â€¯000â€¯ft

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” 12Â B  Header   "MIDX", ver, hashâ€‘algo, chunkâ€‘count, packâ€‘count
â”‚Header  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤ 12Ã—N Chunk table â€“ (ID, offset) pairs sorted by offset
â”‚Chunks  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¦ PNAM â€“ NULâ€‘terminated packfile names
â”‚PNAM    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¦ OIDF â€“ 256Ã—fanout counts (objectâ€‘ID fanout)
â”‚OIDF    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¦ OIDL â€“ sorted list of all object IDs
â”‚OIDL    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¦ OOFF â€“ (packâ€‘ID, 32â€‘bit offset) per object
â”‚OOFF    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¦ LOFF â€“ 64â€‘bit overflow offsets (optional)
â”‚LOFF    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Exactly the same building blocks we met in `.idx`, just stacked sideâ€‘byâ€‘side so one index can describe *every* pack.

---

## âœï¸Â Parsing the MIDX â€“ Walkthrough with Real Code

Below youâ€™ll see trimmed but **literal** excerpts from our production `objstore` package. Each step begins with a oneâ€‘liner *why* and then the exact lines that make it happen. Line numbers and minor errorâ€‘handling have been snipped for brevity; the logic is unchanged.

### 1ï¸âƒ£Â Header sanityâ€‘check

```go
// parseMidx.goÂ â€“ fastâ€‘fail if the file isnâ€™t a real MIDX
var hdr [12]byte
if _, err := mr.ReadAt(hdr[:], 0); err != nil { return nil, err }
if !bytes.Equal(hdr[0:4], []byte("MIDX")) {
    return nil, fmt.Errorf("not a MIDX file")
}

version   := hdr[4]                // v1 or v2
packCount := int(binary.BigEndian.Uint32(hdr[8:12]))
```

### 2ï¸âƒ£Â Chunk directory â€“ turning offsets into a helper

```go
// chunk rows: 4â€‘byte ID + 8â€‘byte offset
cd := make([]struct{ id [4]byte; off uint64 }, chunks+1) // sentinel row
for i := range cd {
    base := int64(12 + i*12)
    _, _ = mr.ReadAt(row[:], base)
    copy(cd[i].id[:], row[0:4])
    cd[i].off = binary.BigEndian.Uint64(row[4:12])
}

sort.Slice(cd, func(i, j int) bool { return cd[i].off < cd[j].off })

findChunk := func(id uint32) (off, size int64, err error) { /* see source */ }
```

### 3ï¸âƒ£Â PNAM â€“ mmap every pack exactly once (thanks, `packCache`)

```go
pnOff, pnSize, _ := findChunk(chunkPNAM)
pn := make([]byte, pnSize)
_, _ = mr.ReadAt(pn, pnOff)

packs := make([]*mmap.ReaderAt, packCount)
for i, start := 0, 0; i < packCount; i++ {
    end := bytes.IndexByte(pn[start:], 0)
    packName := string(pn[start : start+end])
    fullPath := filepath.Join(dir, packName)

    if h, ok := packCache[fullPath]; ok {
        packs[i] = h // reuse handle
    } else {
        packs[i], _ = mmap.Open(fullPath)
        packCache[fullPath] = packs[i]
    }
    start += end + 1
}
```

### 4ï¸âƒ£Â Fanâ€‘out & sorted object IDs

```go
var fanout [256]uint32
fanOff, _, _ := findChunk(chunkOIDF)
_, _ = mr.ReadAt(unsafe.Slice((*byte)(unsafe.Pointer(&fanout[0])), 1024), fanOff)

objCount := fanout[255]

oidOff, _, _ := findChunk(chunkOIDL)
oids := make([]Hash, objCount)
_, _ = mr.ReadAt(unsafe.Slice((*byte)(unsafe.Pointer(&oids[0])), int(objCount*hashSize)), oidOff)
```

### 5ï¸âƒ£Â Offsets (+64â€‘bit spillâ€‘over) & CRC (v2 only)

```go
offOff, _, _ := findChunk(chunkOOFF)
offRaw := make([]byte, objCount*8)
_, _ = mr.ReadAt(offRaw, offOff)

loffOff, loffSize, _ := findChunk(chunkLOFF)
var loff []uint64
if loffSize > 0 {
    loff = make([]uint64, loffSize/8)
    _, _ = mr.ReadAt(unsafe.Slice((*byte)(unsafe.Pointer(&loff[0])), int(loffSize)), loffOff)
}

entries := make([]midxEntry, objCount)
for i := 0; i < int(objCount); i++ {
    packID := binary.BigEndian.Uint32(offRaw[i*8 : i*8+4])
    rawOff := binary.BigEndian.Uint32(offRaw[i*8+4 : i*8+8])

    off64 := uint64(rawOff)
    if rawOff&0x80000000 != 0 { // overflow table lookup
        off64 = loff[rawOff&0x7FFFFFFF]
    }

    entries[i] = midxEntry{packID: packID, offset: off64, crc: crc32IfAny(i)}
}
```

### 6ï¸âƒ£Â Constantâ€‘time lookup

```go
func (m *midxFile) findObject(h Hash) (*mmap.ReaderAt, uint64, bool) {
    first := h[0]
    start := uint32(0)
    if first > 0 { start = m.fanout[first-1] }
    end := m.fanout[first]

    idx, hit := slices.BinarySearchFunc(
        m.objectIDs[start:end], h,
        func(a, b Hash) int { return bytes.Compare(a[:], b[:]) },
    )
    if !hit { return nil, 0, false }

    ent := m.entries[int(start)+idx]
    return m.packReaders[ent.packID], ent.offset, true
}
```

*(Full source, including exhaustive error checks, lives in the project repo; snippets here focus on controlâ€‘flow relevant to the blog.)*

## ğŸš¦Â Packâ€‘Handle Cache â€“ Small Change, Big Win

Mapping the same `.pack` twice wastes both RAM *and* system calls. We fix it with a twoâ€‘liner:

```go
if h, ok := packCache[path]; ok {
    m.packs[i] = h   // already mapped â€“ reuse
} else {
    h, _ := mmap.Open(path)
    m.packs[i] = h
    packCache[path] = h
}
```

On the Linux kernel mirror (127 packs) this drops `open()` from **247 â†’ 3** calls when our scanner chases three objects down a commitÂ â†’ treeÂ â†’ blob chain.

---

## ğŸ”®Â ComingÂ Up â€“ Time to Crack the Pack

We can now pinpoint any object in a multiâ€‘gigabyte repository in microseconds. Next stop: **opening the packfile itself.** In Partâ€¯4 weâ€™ll learn how Git stores objects *compressed* and often as *deltas* of other objects â€“ and how to rebuild them in Go without breaking the bank.

*Stay tuned, and happy (secret) hunting!* ğŸš€

